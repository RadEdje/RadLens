<!doctype html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>RAW </title>
    <link rel="stylesheet" href="./public/css/styles.css">




    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs">
    </script>
    <!-- <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script> -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter@0.2.0"></script>




</head>

<body>
    <!-- <img style="display: none" id="cat" src="high-detail.jpg" width="224" height="224"> -->

    <div>
        <p> THIS HAS TO WORK</p>
    </div>

    <div id="container">
        <video autoplay="true" id="videoElement">

        </video>


        <img id="pic" src="./img/Z.jpg" alt="Smiley face" height="42" width="42">

    </div>




    <footer>

        <!-- for webcam -->
        <script>
            var video = document.querySelector("#videoElement");

            navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia ||
                navigator.msGetUserMedia || navigator.oGetUserMedia;

            if (navigator.getUserMedia) {
                navigator.getUserMedia({
                    video: true
                }, handleVideo, videoError);
            }

            function handleVideo(stream) {
                video.src = window.URL.createObjectURL(stream);
            }

            function videoError(e) {
                alert("error");
            }
        </script>

        <script>
            const MODEL_URL = './model/tensorflowjs_model.pb';
            const WEIGHTS_URL = './model/weights_manifest.json';        
            console.log('before loadFrozenModel')
            async function loadModal() {
                const model = await tf_converter.loadFrozenModel(MODEL_URL, WEIGHTS_URL);
                // console.log(model);             

                let isPredicting = true;
                const predictedClass = tf.tidy(() => {
                    const img = document.getElementById('pic');
                    // const img = tf.fromPixels(document.getElementById("pic"));
                    // const img = tf.fromPixels(document.querySelector("#pic"));
                    // const dimg = img.expandDims(0);
                    console.log(img);
                    // console.log(dimg);
                    console.log(model);
                    // const activation = mobilenet.predict(img);
                    // const predictions = model.predict(activation);
                    // const predictions = model.execute(dimg);
                    const predictions = model.execute({input: tf.fromPixels(img)});

                    return predictions.print();

                });

                console.log(predictedClass);


            }
            loadModal();


            //const cat = document.getElementById('cat');
            //model.execute({input: tf.fromPixels(cat)});

            //FOR THE WEBCAM



            /**
             * A class that wraps webcam video elements to capture Tensor4Ds.
             */
            class Webcam {

                // class Webcam {

                /**
                 * @param {HTMLVideoElement} webcamElement A HTMLVideoElement representing the webcam feed.
                 */
                constructor(webcamElement) {
                    this.webcamElement = webcamElement;
                }

                /**
                 * Captures a frame from the webcam and normalizes it between -1 and 1.
                 * Returns a batched image (1-element batch) of shape [1, w, h, c].
                 */
                capture() {
                    return tf.tidy(() => {
                        // Reads the image as a Tensor from the webcam <video> element.
                        const webcamImage = tf.fromPixels(this.webcamElement);

                        // Crop the image so we're using the center square of the rectangular
                        // webcam.
                        const croppedImage = this.cropImage(webcamImage);

                        // Expand the outer most dimension so we have a batch size of 1.
                        const batchedImage = croppedImage.expandDims(0);

                        // Normalize the image between -1 and 1. The image comes in between 0-255,
                        // so we divide by 127 and subtract 1.
                        return batchedImage.toFloat().div(tf.scalar(127)).sub(tf.scalar(1));
                    });
                }

                /**
                 * Crops an image tensor so we get a square image with no white space.
                 * @param {Tensor4D} img An input image Tensor to crop.
                 */
                cropImage(img) {
                    const size = Math.min(img.shape[0], img.shape[1]);
                    const centerHeight = img.shape[0] / 2;
                    const beginHeight = centerHeight - (size / 2);
                    const centerWidth = img.shape[1] / 2;
                    const beginWidth = centerWidth - (size / 2);
                    return img.slice([beginHeight, beginWidth, 0], [size, size, 3]);
                }

                /**
                 * Adjusts the video size so we can make a centered square crop without
                 * including whitespace.
                 * @param {number} width The real width of the video element.
                 * @param {number} height The real height of the video element.
                 */
                adjustVideoSize(width, height) {
                    const aspectRatio = width / height;
                    if (width >= height) {
                        this.webcamElement.width = aspectRatio * this.webcamElement.height;
                    } else if (width < height) {
                        this.webcamElement.height = this.webcamElement.width / aspectRatio;
                    }
                }

                async setup() {
                    return new Promise((resolve, reject) => {
                        const navigatorAny = navigator;
                        navigator.getUserMedia = navigator.getUserMedia ||
                            navigatorAny.webkitGetUserMedia || navigatorAny.mozGetUserMedia ||
                            navigatorAny.msGetUserMedia;
                        if (navigator.getUserMedia) {
                            navigator.getUserMedia({
                                    video: true
                                },
                                stream => {
                                    this.webcamElement.srcObject = stream;
                                    this.webcamElement.addEventListener('loadeddata', async () => {
                                        this.adjustVideoSize(
                                            this.webcamElement.videoWidth,
                                            this.webcamElement.videoHeight);
                                        resolve();
                                    }, false);
                                },
                                error => {
                                    document.querySelector('#no-webcam').style.display = 'block';
                                });
                        } else {
                            reject();
                        }
                    });
                }



            }

            let webcam = new Webcam(document.querySelector("#videoElement"));
            // const scanner = new Webcam(document.getElementById('#videoElement'));
            console.log(webcam);
            // let isPredicting = true;

            //     const predictedClass = tf.tidy(() => {
            //         const img = tf.fromPixels(document.querySelector("#pic"));
            //         const dimg = img.expandDims(0);
            //         console.log(img);
            //         console.log(dimg);
            //         console.log(fmodel);

            //         // const activation = mobilenet.predict(img);
            //         // const predictions = model.predict(activation);
            //         // const predictions = fmodel.predict(dimg);
            //         // return predictions.print();

            //     });

            //     console.log(predictedClass);




            // THE LOOP FOR LOGGIN PREDICTIONS
            // while (isPredicting) {
            //     const predictedClass = tf.tidy(() => {
            //         const img = webcam.capture();
            //         //   const activation = mobilenet.predict(img);
            //         //   const predictions = model.predict(activation);
            //         const predictions = model.predict(img);
            //         return predictions.as1D().argMax();

            //     });

            //     console.log("predictedClass");

            //     // const classId = (await predictedClass.data())[0];

            //     // console.log(classId);
            //     // // ui.predictClass(classId);
            //     // await tf.nextFrame();

            //     // console.log('while predicting after load');

            // }
        </script>





    </footer>

</body>

</html>